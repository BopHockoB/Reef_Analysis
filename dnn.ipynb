{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:22:52.155322Z",
     "start_time": "2025-11-17T15:22:51.896452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib.pyplot import imread\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Saturday Nov 15 15:34 2025\n",
    "\n",
    "@author: 100yearsahead\n",
    "\n",
    "\n",
    "Bleaching Presence Detection\n",
    "Target variable: Percent_Bleaching\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"./coral-reef-global-bleaching\"\n",
    "filename_read = os.path.join(path, \"coral_whole.csv\")\n",
    "\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "# Removed only locations and labels, no real data touched\n",
    "# df.drop(\"Ocean_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Country_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Sample_ID\", axis=1, inplace=True)\n",
    "# df.drop(\"Date_Year\", axis=1, inplace=True)\n",
    "# df.drop(\"Bleaching_Level\", axis=1, inplace=True)\n",
    "# df.drop(\"Realm_Name\", axis=1, inplace=True)\n",
    "# # #Percent_Cover is not a best predictor and also contain 30% of its fields as null.\n",
    "# # # For the sake of bigger dataset this feature is dropped\n",
    "# df.drop(\"Percent_Cover\", axis=1, inplace=True)\n",
    "# # df.drop(\"ClimSST\", inplace=True, axis=1)\n",
    "# df.drop(\"Exposure\", inplace=True, axis=1)\n",
    "# # df.drop(\"Temperature_Maximum\", inplace=True, axis=1)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Exposure\"] = label_encoder.fit_transform(df[\"Exposure\"])\n",
    "\n",
    "# These features were taken into account that data is nonlinear\n",
    "# df = df[[\"Distance_to_Shore\", \"Temperature_Mean\", \"Turbidity\", \"TSA\", \"Depth_m\", \"Percent_Bleaching\"]]\n",
    "\n",
    "# These features were taken into account that data is linear\n",
    "#df = df[['Cyclone_Frequency', 'Depth_m', 'ClimSST', 'Distance_to_Shore', 'Turbidity', 'TSA', 'Temperature_Mean', 'Percent_Bleaching']]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df  = df.drop(columns=['Sample_ID'])\n",
    "df.info()\n",
    "print(df)\n"
   ],
   "id": "d13e72dd95c6d234",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22561 entries, 6981 to 35042\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Cyclone_Frequency    22561 non-null  float64\n",
      " 1   Depth_m              22561 non-null  float64\n",
      " 2   ClimSST              22561 non-null  float64\n",
      " 3   Ocean_Name           22561 non-null  object \n",
      " 4   Country_Name         22561 non-null  object \n",
      " 5   Distance_to_Shore    22561 non-null  float64\n",
      " 6   Exposure             22561 non-null  object \n",
      " 7   Turbidity            22561 non-null  float64\n",
      " 8   Date_Year            22561 non-null  int64  \n",
      " 9   Bleaching_Level      22561 non-null  object \n",
      " 10  Temperature_Maximum  22561 non-null  float64\n",
      " 11  SSTA                 22561 non-null  float64\n",
      " 12  TSA                  22561 non-null  float64\n",
      " 13  Percent_Bleaching    22561 non-null  float64\n",
      " 14  Temperature_Mean     22561 non-null  float64\n",
      " 15  Realm_Name           22561 non-null  object \n",
      " 16  Percent_Cover        22561 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(5)\n",
      "memory usage: 3.1+ MB\n",
      "       Cyclone_Frequency  Depth_m  ClimSST Ocean_Name   Country_Name  \\\n",
      "6981               43.39      4.0   300.52    Pacific      Australia   \n",
      "6982               43.39      4.0   300.52    Pacific      Australia   \n",
      "6983               43.97      5.0   299.07    Pacific      Australia   \n",
      "6984               43.97      5.0   299.07    Pacific      Australia   \n",
      "6985               43.97      4.0   299.02    Pacific      Australia   \n",
      "...                  ...      ...      ...        ...            ...   \n",
      "35038              50.27      5.0   302.47    Pacific       Thailand   \n",
      "35039              50.27      5.0   302.47    Pacific       Thailand   \n",
      "35040              85.57      3.0   300.97   Atlantic  United States   \n",
      "35041              85.57      3.0   300.97   Atlantic  United States   \n",
      "35042              35.71     14.0   301.58     Indian     Madagascar   \n",
      "\n",
      "       Distance_to_Shore   Exposure  Turbidity  Date_Year Bleaching_Level  \\\n",
      "6981              126.24  Sometimes     0.1384       2006      Population   \n",
      "6982              126.24  Sometimes     0.1384       2006      Population   \n",
      "6983            19577.87    Exposed     0.0599       2005      Population   \n",
      "6984            19577.87    Exposed     0.0599       2005      Population   \n",
      "6985            19577.87    Exposed     0.0599       2004      Population   \n",
      "...                  ...        ...        ...        ...             ...   \n",
      "35038              73.88    Exposed     0.0565       2014      Population   \n",
      "35039              73.88    Exposed     0.0565       2014      Population   \n",
      "35040              49.16  Sheltered     0.0586       2005      Population   \n",
      "35041              49.16  Sheltered     0.0586       2005      Population   \n",
      "35042            8768.03  Sometimes     0.0628       2016          Colony   \n",
      "\n",
      "       Temperature_Maximum  SSTA   TSA  Percent_Bleaching  Temperature_Mean  \\\n",
      "6981                305.77 -0.32 -4.29                0.0            299.07   \n",
      "6982                305.77 -0.32 -4.29                0.0            299.07   \n",
      "6983                304.85 -0.59 -0.59                0.0            299.05   \n",
      "6984                304.85 -0.59 -0.59                0.0            299.05   \n",
      "6985                304.85  4.61  4.54                0.0            299.05   \n",
      "...                    ...   ...   ...                ...               ...   \n",
      "35038               306.89  1.40  1.26              100.0            302.00   \n",
      "35039               306.89  1.40  1.26              100.0            302.00   \n",
      "35040               303.67  0.32  0.21              100.0            300.34   \n",
      "35041               303.67  0.32  0.21              100.0            300.34   \n",
      "35042               305.32  0.63  0.59              100.0            301.26   \n",
      "\n",
      "                 Realm_Name  Percent_Cover  \n",
      "6981   Central Indo-Pacific          29.38  \n",
      "6982   Central Indo-Pacific           0.62  \n",
      "6983   Central Indo-Pacific           5.00  \n",
      "6984   Central Indo-Pacific          31.25  \n",
      "6985   Central Indo-Pacific           0.00  \n",
      "...                     ...            ...  \n",
      "35038  Central Indo-Pacific          75.62  \n",
      "35039  Central Indo-Pacific           0.00  \n",
      "35040     Tropical Atlantic          28.75  \n",
      "35041     Tropical Atlantic           5.62  \n",
      "35042  Western Indo-Pacific          19.06  \n",
      "\n",
      "[22561 rows x 17 columns]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:22:54.173277Z",
     "start_time": "2025-11-17T15:22:54.053115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Split first (no leakage)\n",
    "X = df.drop(columns=['Percent_Bleaching'])\n",
    "y = df['Percent_Bleaching']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Since we have categorical variables we need to seperate the numeric and the categorical variables\n",
    "cat_cols = ['Realm_Name','Ocean_Name','Country_Name','Exposure','Bleaching_Level']\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "\n",
    "\n",
    "# We one_hot_encode the categorical features\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = ohe.fit_transform(X_train[cat_cols])\n",
    "X_test_cat  = ohe.transform(X_test[cat_cols])\n",
    "\n",
    "\n",
    "# We scale the numeric features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_num  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "# Combine the categorical and numerical features\n",
    "X_train_processed = np.hstack([X_train_num, X_train_cat])\n",
    "X_test_processed  = np.hstack([X_test_num, X_test_cat])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c9a3227fa44bb497",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:22:55.738220Z",
     "start_time": "2025-11-17T15:22:55.638960Z"
    }
   },
   "source": [
    "\n",
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "nodes_number = int((X_train_processed.shape[1] + 1) * 2/3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape= (X_train_processed.shape[1],)))\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m70\u001B[0m)             │         \u001B[38;5;34m7,350\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m70\u001B[0m)             │         \u001B[38;5;34m4,970\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m70\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m71\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,350</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,970</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m12,391\u001B[0m (48.40 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,391</span> (48.40 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m12,391\u001B[0m (48.40 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,391</span> (48.40 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "3b6c415cf8a8b36b",
   "metadata": {},
   "source": [
    "Install cuda toolkit for GPU on desktop\n",
    "\n",
    "Tensorflow GPU version (maybe try conda env)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:36:51.864009Z",
     "start_time": "2025-11-17T15:35:28.738563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    monitor='loss'\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mse\",\n",
    "              metrics=['mae'],\n",
    "               )\n",
    "\n",
    "model.fit(X_train_processed, y_train, epochs=200, verbose=2, callbacks=[early_stop])\n",
    "\n",
    "model.summary()"
   ],
   "id": "f31865e6d221b7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "564/564 - 3s - 5ms/step - loss: 22.6946 - mae: 2.2909\n",
      "Epoch 2/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.0973 - mae: 2.2648\n",
      "Epoch 3/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.4229 - mae: 2.2557\n",
      "Epoch 4/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.4272 - mae: 2.2539\n",
      "Epoch 5/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.3025 - mae: 2.2589\n",
      "Epoch 6/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.3442 - mae: 2.2661\n",
      "Epoch 7/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.3977 - mae: 2.2641\n",
      "Epoch 8/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.8866 - mae: 2.2554\n",
      "Epoch 9/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.6805 - mae: 2.2464\n",
      "Epoch 10/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.3502 - mae: 2.2249\n",
      "Epoch 11/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.3898 - mae: 2.2410\n",
      "Epoch 12/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.9308 - mae: 2.2509\n",
      "Epoch 13/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.4817 - mae: 2.2353\n",
      "Epoch 14/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.0272 - mae: 2.2368\n",
      "Epoch 15/200\n",
      "564/564 - 1s - 2ms/step - loss: 22.1790 - mae: 2.2586\n",
      "Epoch 16/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.1315 - mae: 2.2360\n",
      "Epoch 17/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.2764 - mae: 2.2358\n",
      "Epoch 18/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.3254 - mae: 2.2289\n",
      "Epoch 19/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.7662 - mae: 2.2361\n",
      "Epoch 20/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.5197 - mae: 2.2402\n",
      "Epoch 21/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.0530 - mae: 2.2125\n",
      "Epoch 22/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.7345 - mae: 2.2396\n",
      "Epoch 23/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.4539 - mae: 2.2186\n",
      "Epoch 24/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.0237 - mae: 2.2055\n",
      "Epoch 25/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.9447 - mae: 2.2188\n",
      "Epoch 26/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.5872 - mae: 2.2430\n",
      "Epoch 27/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.6414 - mae: 2.2120\n",
      "Epoch 28/200\n",
      "564/564 - 2s - 3ms/step - loss: 21.1051 - mae: 2.2007\n",
      "Epoch 29/200\n",
      "564/564 - 1s - 3ms/step - loss: 21.3328 - mae: 2.2239\n",
      "Epoch 30/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.3693 - mae: 2.1704\n",
      "Epoch 31/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.8918 - mae: 2.2120\n",
      "Epoch 32/200\n",
      "564/564 - 2s - 3ms/step - loss: 20.1750 - mae: 2.1952\n",
      "Epoch 33/200\n",
      "564/564 - 2s - 3ms/step - loss: 20.9684 - mae: 2.2170\n",
      "Epoch 34/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.6654 - mae: 2.1838\n",
      "Epoch 35/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.6948 - mae: 2.1941\n",
      "Epoch 36/200\n",
      "564/564 - 2s - 3ms/step - loss: 20.9001 - mae: 2.2056\n",
      "Epoch 37/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.8530 - mae: 2.2015\n",
      "Epoch 38/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.1153 - mae: 2.1891\n",
      "Epoch 39/200\n",
      "564/564 - 1s - 2ms/step - loss: 19.8347 - mae: 2.1630\n",
      "Epoch 40/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.0208 - mae: 2.1770\n",
      "Epoch 41/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.5879 - mae: 2.2075\n",
      "Epoch 42/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.6931 - mae: 2.1885\n",
      "Epoch 43/200\n",
      "564/564 - 1s - 2ms/step - loss: 21.0726 - mae: 2.2081\n",
      "Epoch 44/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.0257 - mae: 2.1719\n",
      "Epoch 45/200\n",
      "564/564 - 2s - 3ms/step - loss: 19.7219 - mae: 2.1575\n",
      "Epoch 46/200\n",
      "564/564 - 2s - 3ms/step - loss: 20.2615 - mae: 2.1659\n",
      "Epoch 47/200\n",
      "564/564 - 1s - 3ms/step - loss: 20.8819 - mae: 2.1927\n",
      "Epoch 48/200\n",
      "564/564 - 2s - 3ms/step - loss: 20.9623 - mae: 2.2144\n",
      "Epoch 49/200\n",
      "564/564 - 1s - 2ms/step - loss: 19.4102 - mae: 2.1484\n",
      "Epoch 50/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.5750 - mae: 2.1849\n",
      "Epoch 51/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.3642 - mae: 2.1829\n",
      "Epoch 52/200\n",
      "564/564 - 1s - 2ms/step - loss: 19.8127 - mae: 2.1552\n",
      "Epoch 53/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.1185 - mae: 2.1504\n",
      "Epoch 54/200\n",
      "564/564 - 1s - 2ms/step - loss: 19.8330 - mae: 2.1574\n",
      "Epoch 55/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.1471 - mae: 2.1496\n",
      "Epoch 56/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.0171 - mae: 2.1586\n",
      "Epoch 57/200\n",
      "564/564 - 1s - 2ms/step - loss: 20.3811 - mae: 2.1708\n",
      "Epoch 58/200\n",
      "564/564 - 1s - 2ms/step - loss: 19.5277 - mae: 2.1425\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      3\u001B[39m early_stop = EarlyStopping(\n\u001B[32m      4\u001B[39m     patience=\u001B[32m10\u001B[39m,\n\u001B[32m      5\u001B[39m     restore_best_weights=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      6\u001B[39m     monitor=\u001B[33m'\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      7\u001B[39m )\n\u001B[32m      9\u001B[39m model.compile(optimizer=\u001B[33m\"\u001B[39m\u001B[33madam\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     10\u001B[39m               loss=\u001B[33m\"\u001B[39m\u001B[33mmse\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     11\u001B[39m               metrics=[\u001B[33m'\u001B[39m\u001B[33mmae\u001B[39m\u001B[33m'\u001B[39m],\n\u001B[32m     12\u001B[39m                )\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_processed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mearly_stop\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m model.summary()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    116\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m117\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001B[39m, in \u001B[36mTensorFlowTrainer.fit\u001B[39m\u001B[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[39m\n\u001B[32m    397\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m begin_step, end_step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[32m    398\u001B[39m     callbacks.on_train_batch_begin(begin_step)\n\u001B[32m--> \u001B[39m\u001B[32m399\u001B[39m     logs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    400\u001B[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001B[32m    401\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stop_training:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:242\u001B[39m, in \u001B[36mTensorFlowTrainer._make_function.<locals>.function\u001B[39m\u001B[34m(iterator)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[32m    239\u001B[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001B[32m    240\u001B[39m ):\n\u001B[32m    241\u001B[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mopt_outputs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhas_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    243\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[32m    244\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m opt_outputs.get_value()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:176\u001B[39m, in \u001B[36m_OptionalImpl.has_value\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhas_value\u001B[39m(\u001B[38;5;28mself\u001B[39m, name=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    175\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ops.colocate_with(\u001B[38;5;28mself\u001B[39m._variant_tensor):\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_optional_ops\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptional_has_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variant_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:172\u001B[39m, in \u001B[36moptional_has_value\u001B[39m\u001B[34m(optional, name)\u001B[39m\n\u001B[32m    170\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tld.is_eager:\n\u001B[32m    171\u001B[39m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m     _result = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mOptionalHasValue\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptional\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    174\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[32m    175\u001B[39m   \u001B[38;5;28;01mexcept\u001B[39;00m _core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T15:37:02.732043Z",
     "start_time": "2025-11-17T15:37:02.189249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(score)\n",
    "print(mean_squared_error(y_test, y_pred))"
   ],
   "id": "5a4427fd05bff643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m142/142\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n",
      "0.6296280480634995\n",
      "43.55836051927799\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "it takes absurd amount of time to make a very poor predict prediction, probably need to preprocess data again\n",
    "\n",
    "Best score with such settings\n",
    "\n",
    "nodes_number = int((X.shape[1] + 1) * 2/3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape= (X.shape[1],)))\n",
    "\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "with standard scaler data applied to both X and y\n",
    "\n",
    "0.21329008825613271\n",
    "\n",
    "0.7689129542072395\n",
    "\n",
    "Probably it worth to try use 62 features with location and timestamps excluded. Could possibly apply PCA\n"
   ],
   "id": "b320f1325b72a36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:50:00.036798Z",
     "start_time": "2025-11-14T23:49:58.985808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import Sequential\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 29 15:40:04 2025\n",
    "\n",
    "@author: zemsk\n",
    "\n",
    "\n",
    "Bleaching Presence Detection\n",
    "Target variable: Percent_Bleaching\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"./coral-reef-global-bleaching\"\n",
    "filename_read = os.path.join(path, \"coral.csv\")\n",
    "\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "# # Removed only locations and labels, no real data touched\n",
    "# df.drop(\"Ocean_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Country_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Sample_ID\", axis=1, inplace=True)\n",
    "# df.drop(\"Date_Year\", axis=1, inplace=True)\n",
    "# df.drop(\"Bleaching_Level\", axis=1, inplace=True)\n",
    "# df.drop(\"Realm_Name\", axis=1, inplace=True)\n",
    "#\n",
    "# cols_to_drop = [\n",
    "#     'Site_ID', 'Data_Source', 'Latitude_Degrees', 'Longitude_Degrees',\n",
    "#     'Reef_ID', 'Ecoregion_Name', 'State_Island_Province_Name',\n",
    "#     'City_Town_Name', 'Site_Name', 'Date', 'Date_Day', 'Date_Month',\n",
    "#     'Site_Comments', 'Sample_Comments', 'Bleaching_Comments'\n",
    "# ]\n",
    "#\n",
    "# df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "# #Percent_Cover is not a best predictor and also contain 30% of its fields as null.\n",
    "# # For the sake of bigger dataset this feature is dropped\n",
    "# df.drop(\"Percent_Cover\", axis=1, inplace=True)\n",
    "# df.drop(\"ClimSST\", inplace=True, axis=1)\n",
    "# df.drop(\"Exposure\", inplace=True, axis=1)\n",
    "# df.drop(\"Temperature_Maximum\", inplace=True, axis=1)\n",
    "#\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Exposure\"] = label_encoder.fit_transform(df[\"Exposure\"])\n",
    "\n",
    "# These features were taken into account that data is nonlinear\n",
    "#df = df[[\"Distance_to_Shore\", \"Temperature_Mean\", \"Turbidity\", \"TSA\", \"Depth_m\", \"Percent_Bleaching\"]]\n",
    "\n",
    "# These features were taken into account that data is linear\n",
    "# df = df[['Cyclone_Frequency', 'Depth_m', 'ClimSST', 'Distance_to_Shore', 'Turbidity', 'TSA', 'Temperature_Mean', 'Percent_Bleaching']]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "\n"
   ],
   "id": "76100a6c4c33eb3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zemsk\\AppData\\Local\\Temp\\ipykernel_16180\\3720938078.py:27: DtypeWarning: Columns (13,15,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename_read)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41361 entries, 0 to 41360\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Site_ID                                41361 non-null  int64  \n",
      " 1   Sample_ID                              41361 non-null  int64  \n",
      " 2   Data_Source                            41361 non-null  object \n",
      " 3   Latitude_Degrees                       41361 non-null  float64\n",
      " 4   Longitude_Degrees                      41361 non-null  float64\n",
      " 5   Ocean_Name                             41361 non-null  object \n",
      " 6   Reef_ID                                41361 non-null  object \n",
      " 7   Realm_Name                             41361 non-null  object \n",
      " 8   Ecoregion_Name                         41361 non-null  object \n",
      " 9   Country_Name                           41361 non-null  object \n",
      " 10  State_Island_Province_Name             41361 non-null  object \n",
      " 11  City_Town_Name                         41361 non-null  object \n",
      " 12  Site_Name                              41361 non-null  object \n",
      " 13  Distance_to_Shore                      41361 non-null  object \n",
      " 14  Exposure                               41361 non-null  object \n",
      " 15  Turbidity                              41361 non-null  object \n",
      " 16  Cyclone_Frequency                      41361 non-null  float64\n",
      " 17  Date_Day                               41361 non-null  int64  \n",
      " 18  Date_Month                             41361 non-null  int64  \n",
      " 19  Date_Year                              41361 non-null  int64  \n",
      " 20  Depth_m                                41361 non-null  object \n",
      " 21  Substrate_Name                         41361 non-null  object \n",
      " 22  Percent_Cover                          41361 non-null  object \n",
      " 23  Bleaching_Level                        41361 non-null  object \n",
      " 24  Percent_Bleaching                      41361 non-null  object \n",
      " 25  ClimSST                                41361 non-null  object \n",
      " 26  Temperature_Kelvin                     41361 non-null  object \n",
      " 27  Temperature_Mean                       41361 non-null  object \n",
      " 28  Temperature_Minimum                    41361 non-null  object \n",
      " 29  Temperature_Maximum                    41361 non-null  object \n",
      " 30  Temperature_Kelvin_Standard_Deviation  41361 non-null  object \n",
      " 31  Windspeed                              41361 non-null  object \n",
      " 32  SSTA                                   41361 non-null  object \n",
      " 33  SSTA_Standard_Deviation                41361 non-null  object \n",
      " 34  SSTA_Mean                              41361 non-null  object \n",
      " 35  SSTA_Minimum                           41361 non-null  object \n",
      " 36  SSTA_Maximum                           41361 non-null  object \n",
      " 37  SSTA_Frequency                         41361 non-null  object \n",
      " 38  SSTA_Frequency_Standard_Deviation      41361 non-null  object \n",
      " 39  SSTA_FrequencyMax                      41361 non-null  object \n",
      " 40  SSTA_FrequencyMean                     41361 non-null  object \n",
      " 41  SSTA_DHW                               41361 non-null  object \n",
      " 42  SSTA_DHW_Standard_Deviation            41361 non-null  object \n",
      " 43  SSTA_DHWMax                            41361 non-null  object \n",
      " 44  SSTA_DHWMean                           41361 non-null  object \n",
      " 45  TSA                                    41361 non-null  object \n",
      " 46  TSA_Standard_Deviation                 41361 non-null  object \n",
      " 47  TSA_Minimum                            41361 non-null  object \n",
      " 48  TSA_Maximum                            41361 non-null  object \n",
      " 49  TSA_Mean                               41361 non-null  object \n",
      " 50  TSA_Frequency                          41361 non-null  object \n",
      " 51  TSA_Frequency_Standard_Deviation       41361 non-null  object \n",
      " 52  TSA_FrequencyMax                       41361 non-null  object \n",
      " 53  TSA_FrequencyMean                      41361 non-null  object \n",
      " 54  TSA_DHW                                41361 non-null  object \n",
      " 55  TSA_DHW_Standard_Deviation             41361 non-null  object \n",
      " 56  TSA_DHWMax                             41361 non-null  object \n",
      " 57  TSA_DHWMean                            41361 non-null  object \n",
      " 58  Date                                   41361 non-null  object \n",
      " 59  Site_Comments                          41361 non-null  object \n",
      " 60  Sample_Comments                        41361 non-null  object \n",
      " 61  Bleaching_Comments                     41361 non-null  object \n",
      "dtypes: float64(3), int64(5), object(54)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
