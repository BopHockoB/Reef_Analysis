{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:38:50.969069Z",
     "start_time": "2025-11-20T15:38:50.738933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib.pyplot import imread\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Saturday Nov 15 15:34 2025\n",
    "\n",
    "@author: 100yearsahead\n",
    "\n",
    "\n",
    "Bleaching Presence Detection\n",
    "Target variable: Percent_Bleaching\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"./coral-reef-global-bleaching\"\n",
    "filename_read = os.path.join(path, \"coral_whole.csv\")\n",
    "\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "# Removed only locations and labels, no real data touched\n",
    "# df.drop(\"Ocean_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Country_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Sample_ID\", axis=1, inplace=True)\n",
    "# df.drop(\"Date_Year\", axis=1, inplace=True)\n",
    "# df.drop(\"Bleaching_Level\", axis=1, inplace=True)\n",
    "# df.drop(\"Realm_Name\", axis=1, inplace=True)\n",
    "# # #Percent_Cover is not a best predictor and also contain 30% of its fields as null.\n",
    "# # # For the sake of bigger dataset this feature is dropped\n",
    "# df.drop(\"Percent_Cover\", axis=1, inplace=True)\n",
    "# # df.drop(\"ClimSST\", inplace=True, axis=1)\n",
    "# df.drop(\"Exposure\", inplace=True, axis=1)\n",
    "# # df.drop(\"Temperature_Maximum\", inplace=True, axis=1)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Exposure\"] = label_encoder.fit_transform(df[\"Exposure\"])\n",
    "\n",
    "# These features were taken into account that data is nonlinear\n",
    "# df = df[[\"Distance_to_Shore\", \"Temperature_Mean\", \"Turbidity\", \"TSA\", \"Depth_m\", \"Percent_Bleaching\"]]\n",
    "\n",
    "# These features were taken into account that data is linear\n",
    "#df = df[['Cyclone_Frequency', 'Depth_m', 'ClimSST', 'Distance_to_Shore', 'Turbidity', 'TSA', 'Temperature_Mean', 'Percent_Bleaching']]\n",
    "\n",
    "df  = df.drop(columns=['Sample_ID', 'Percent_Cover'])\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.info()\n",
    "print(df)\n"
   ],
   "id": "d13e72dd95c6d234",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32714 entries, 0 to 35044\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Cyclone_Frequency    32714 non-null  float64\n",
      " 1   Depth_m              32714 non-null  float64\n",
      " 2   ClimSST              32714 non-null  float64\n",
      " 3   Ocean_Name           32714 non-null  object \n",
      " 4   Country_Name         32714 non-null  object \n",
      " 5   Distance_to_Shore    32714 non-null  float64\n",
      " 6   Exposure             32714 non-null  object \n",
      " 7   Turbidity            32714 non-null  float64\n",
      " 8   Date_Year            32714 non-null  int64  \n",
      " 9   Bleaching_Level      32714 non-null  object \n",
      " 10  Temperature_Maximum  32714 non-null  float64\n",
      " 11  SSTA                 32714 non-null  float64\n",
      " 12  TSA                  32714 non-null  float64\n",
      " 13  Percent_Bleaching    32714 non-null  float64\n",
      " 14  Temperature_Mean     32714 non-null  float64\n",
      " 15  Realm_Name           32714 non-null  object \n",
      "dtypes: float64(10), int64(1), object(5)\n",
      "memory usage: 4.2+ MB\n",
      "       Cyclone_Frequency  Depth_m  ClimSST Ocean_Name      Country_Name  \\\n",
      "0                  49.90    10.00   301.61   Atlantic              Cuba   \n",
      "1                  51.20    14.00   262.15    Pacific  French Polynesia   \n",
      "2                  61.52     7.00   298.79   Atlantic    United Kingdom   \n",
      "3                  65.39     9.02   300.16   Atlantic     United States   \n",
      "4                  65.39    12.50   300.15   Atlantic     United States   \n",
      "...                  ...      ...      ...        ...               ...   \n",
      "35040              85.57     3.00   300.97   Atlantic     United States   \n",
      "35041              85.57     3.00   300.97   Atlantic     United States   \n",
      "35042              35.71    14.00   301.58     Indian        Madagascar   \n",
      "35043              58.42     4.00   299.79   Atlantic     United States   \n",
      "35044              62.54     4.00   298.32   Atlantic     United States   \n",
      "\n",
      "       Distance_to_Shore   Exposure  Turbidity  Date_Year Bleaching_Level  \\\n",
      "0                8519.23    Exposed     0.0287       2005          Colony   \n",
      "1                1431.62    Exposed     0.0262       1991          Colony   \n",
      "2                 182.33    Exposed     0.0429       2006          Colony   \n",
      "3                 313.13    Exposed     0.0424       2006          Colony   \n",
      "4                 792.00    Exposed     0.0424       2006          Colony   \n",
      "...                  ...        ...        ...        ...             ...   \n",
      "35040              49.16  Sheltered     0.0586       2005      Population   \n",
      "35041              49.16  Sheltered     0.0586       2005      Population   \n",
      "35042            8768.03  Sometimes     0.0628       2016          Colony   \n",
      "35043            8170.00    Exposed     0.1203       2015          Colony   \n",
      "35044            1863.00  Sheltered     0.1703       2015          Colony   \n",
      "\n",
      "       Temperature_Maximum  SSTA   TSA  Percent_Bleaching  Temperature_Mean  \\\n",
      "0                   304.69 -0.46 -0.80               50.2            300.67   \n",
      "1                   305.01  1.29  1.29               50.7            300.73   \n",
      "2                   304.14  0.04 -2.64               50.9            300.32   \n",
      "3                   304.07 -0.07 -2.27               50.9            300.38   \n",
      "4                   303.76  0.00 -2.19               50.9            300.38   \n",
      "...                    ...   ...   ...                ...               ...   \n",
      "35040               303.67  0.32  0.21              100.0            300.34   \n",
      "35041               303.67  0.32  0.21              100.0            300.34   \n",
      "35042               305.32  0.63  0.59              100.0            301.26   \n",
      "35043               306.04  3.91  3.91              100.0            299.79   \n",
      "35044               306.82  1.59 -0.57              100.0            299.65   \n",
      "\n",
      "                 Realm_Name  \n",
      "0         Tropical Atlantic  \n",
      "1      Eastern Indo-Pacific  \n",
      "2         Tropical Atlantic  \n",
      "3         Tropical Atlantic  \n",
      "4         Tropical Atlantic  \n",
      "...                     ...  \n",
      "35040     Tropical Atlantic  \n",
      "35041     Tropical Atlantic  \n",
      "35042  Western Indo-Pacific  \n",
      "35043     Tropical Atlantic  \n",
      "35044     Tropical Atlantic  \n",
      "\n",
      "[32714 rows x 16 columns]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:38:57.032439Z",
     "start_time": "2025-11-20T15:38:53.008005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "skewness_results = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    clean_data = df[col].dropna()\n",
    "    if len(clean_data) > 0:\n",
    "        skew_val = skew(clean_data)\n",
    "        skewness_results[col] = {\n",
    "            'skewness': skew_val,\n",
    "            'skew_type': 'Right (Positive)' if skew_val > 0.5 else 'Left (Negative)' if skew_val < -0.5 else 'Approximately Symmetric',\n",
    "\n",
    "        }\n",
    "\n",
    "right_skewed = {col: data for col, data in skewness_results.items() if data['skewness'] > 0.5}\n",
    "left_skewed = {col: data for col, data in skewness_results.items() if data['skewness'] < -0.5}\n",
    "\n",
    "print(left_skewed.keys())\n",
    "print(right_skewed.keys())\n",
    "for col_right in right_skewed.keys():\n",
    "    df[col_right] = df[col_right].replace(0, 1e-6)\n",
    "    df[col_right], lam = boxcox(df[col_right])\n",
    "\n",
    "for col_left in left_skewed.keys():\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    df[[col_left]] = pt.fit_transform(df[[col_left]])\n",
    "\n",
    "skewness_df = pd.DataFrame(skewness_results).T\n",
    "skewness_df = skewness_df.sort_values('skewness', key=abs, ascending=False)\n",
    "skewness_df[:-1]"
   ],
   "id": "d0cc5e066125b8ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ClimSST', 'TSA', 'Temperature_Mean'])\n",
      "dict_keys(['Cyclone_Frequency', 'Depth_m', 'Distance_to_Shore', 'Turbidity', 'Temperature_Maximum', 'Percent_Bleaching'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zemsk\\anaconda3\\Lib\\site-packages\\numpy\\_core\\_methods.py:197: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\zemsk\\anaconda3\\Lib\\site-packages\\numpy\\_core\\_methods.py:208: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     skewness                skew_type\n",
       "Distance_to_Shore    9.390477         Right (Positive)\n",
       "Turbidity            3.848336         Right (Positive)\n",
       "Percent_Bleaching    2.969849         Right (Positive)\n",
       "ClimSST             -1.640544          Left (Negative)\n",
       "Temperature_Mean    -1.320474          Left (Negative)\n",
       "Depth_m              1.272371         Right (Positive)\n",
       "TSA                 -1.013456          Left (Negative)\n",
       "Temperature_Maximum  0.930379         Right (Positive)\n",
       "Cyclone_Frequency    0.891588         Right (Positive)\n",
       "SSTA                 0.198355  Approximately Symmetric"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skewness</th>\n",
       "      <th>skew_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Distance_to_Shore</th>\n",
       "      <td>9.390477</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turbidity</th>\n",
       "      <td>3.848336</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percent_Bleaching</th>\n",
       "      <td>2.969849</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClimSST</th>\n",
       "      <td>-1.640544</td>\n",
       "      <td>Left (Negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature_Mean</th>\n",
       "      <td>-1.320474</td>\n",
       "      <td>Left (Negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depth_m</th>\n",
       "      <td>1.272371</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSA</th>\n",
       "      <td>-1.013456</td>\n",
       "      <td>Left (Negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature_Maximum</th>\n",
       "      <td>0.930379</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyclone_Frequency</th>\n",
       "      <td>0.891588</td>\n",
       "      <td>Right (Positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSTA</th>\n",
       "      <td>0.198355</td>\n",
       "      <td>Approximately Symmetric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:38:59.711599Z",
     "start_time": "2025-11-20T15:38:59.572632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Split first (no leakage)\n",
    "X = df.drop(columns=['Percent_Bleaching'])\n",
    "y = df['Percent_Bleaching']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Since we have categorical variables we need to seperate the numeric and the categorical variables\n",
    "cat_cols = ['Realm_Name','Ocean_Name','Country_Name','Exposure','Bleaching_Level']\n",
    "num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "\n",
    "\n",
    "# We one_hot_encode the categorical features\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "X_train_cat = ohe.fit_transform(X_train[cat_cols])\n",
    "X_test_cat  = ohe.transform(X_test[cat_cols])\n",
    "\n",
    "\n",
    "# We scale the numeric features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_num  = scaler.transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "# Combine the categorical and numerical features\n",
    "X_train_processed = np.hstack([X_train_num, X_train_cat])\n",
    "X_test_processed  = np.hstack([X_test_num, X_test_cat])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "c9a3227fa44bb497",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:39:03.258146Z",
     "start_time": "2025-11-20T15:39:03.129358Z"
    }
   },
   "source": [
    "\n",
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "nodes_number = int((X_train_processed.shape[1] + 1) * 2/3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape= (X_train_processed.shape[1],)))\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m74\u001B[0m)             │         \u001B[38;5;34m8,214\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m74\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m74\u001B[0m)             │         \u001B[38;5;34m5,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m74\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m75\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,214</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m13,839\u001B[0m (54.06 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,839</span> (54.06 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m13,839\u001B[0m (54.06 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,839</span> (54.06 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "3b6c415cf8a8b36b",
   "metadata": {},
   "source": [
    "Install cuda toolkit for GPU on desktop\n",
    "\n",
    "Tensorflow GPU version (maybe try conda env)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:40:53.222060Z",
     "start_time": "2025-11-20T15:39:07.299509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    monitor='loss'\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mse\",\n",
    "              metrics=['mae'],\n",
    "               )\n",
    "\n",
    "model.fit(X_train_processed, y_train, epochs=200, verbose=2, callbacks=[early_stop])\n",
    "\n",
    "model.summary()"
   ],
   "id": "f31865e6d221b7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "818/818 - 4s - 5ms/step - loss: 49.4247 - mae: 5.8647\n",
      "Epoch 2/200\n",
      "818/818 - 2s - 3ms/step - loss: 42.5265 - mae: 5.2147\n",
      "Epoch 3/200\n",
      "818/818 - 2s - 3ms/step - loss: 41.1541 - mae: 5.0685\n",
      "Epoch 4/200\n",
      "818/818 - 2s - 3ms/step - loss: 40.3140 - mae: 4.9790\n",
      "Epoch 5/200\n",
      "818/818 - 3s - 3ms/step - loss: 39.3611 - mae: 4.9001\n",
      "Epoch 6/200\n",
      "818/818 - 2s - 3ms/step - loss: 38.8414 - mae: 4.8488\n",
      "Epoch 7/200\n",
      "818/818 - 2s - 3ms/step - loss: 38.3665 - mae: 4.8031\n",
      "Epoch 8/200\n",
      "818/818 - 2s - 3ms/step - loss: 38.0005 - mae: 4.7776\n",
      "Epoch 9/200\n",
      "818/818 - 2s - 3ms/step - loss: 37.3861 - mae: 4.7154\n",
      "Epoch 10/200\n",
      "818/818 - 2s - 3ms/step - loss: 37.0150 - mae: 4.6843\n",
      "Epoch 11/200\n",
      "818/818 - 2s - 3ms/step - loss: 36.7495 - mae: 4.6684\n",
      "Epoch 12/200\n",
      "818/818 - 2s - 3ms/step - loss: 36.3517 - mae: 4.6269\n",
      "Epoch 13/200\n",
      "818/818 - 2s - 3ms/step - loss: 36.0018 - mae: 4.5958\n",
      "Epoch 14/200\n",
      "818/818 - 2s - 3ms/step - loss: 35.7882 - mae: 4.5741\n",
      "Epoch 15/200\n",
      "818/818 - 2s - 3ms/step - loss: 35.4149 - mae: 4.5478\n",
      "Epoch 16/200\n",
      "818/818 - 2s - 3ms/step - loss: 35.1590 - mae: 4.5220\n",
      "Epoch 17/200\n",
      "818/818 - 2s - 3ms/step - loss: 35.2197 - mae: 4.5228\n",
      "Epoch 18/200\n",
      "818/818 - 2s - 3ms/step - loss: 34.7026 - mae: 4.4833\n",
      "Epoch 19/200\n",
      "818/818 - 2s - 3ms/step - loss: 34.5291 - mae: 4.4703\n",
      "Epoch 20/200\n",
      "818/818 - 2s - 3ms/step - loss: 34.4260 - mae: 4.4562\n",
      "Epoch 21/200\n",
      "818/818 - 2s - 3ms/step - loss: 34.1402 - mae: 4.4348\n",
      "Epoch 22/200\n",
      "818/818 - 2s - 3ms/step - loss: 34.0617 - mae: 4.4279\n",
      "Epoch 23/200\n",
      "818/818 - 2s - 3ms/step - loss: 33.7855 - mae: 4.4090\n",
      "Epoch 24/200\n",
      "818/818 - 3s - 3ms/step - loss: 33.5596 - mae: 4.3870\n",
      "Epoch 25/200\n",
      "818/818 - 2s - 3ms/step - loss: 33.4589 - mae: 4.3843\n",
      "Epoch 26/200\n",
      "818/818 - 2s - 3ms/step - loss: 33.1740 - mae: 4.3433\n",
      "Epoch 27/200\n",
      "818/818 - 2s - 3ms/step - loss: 33.2442 - mae: 4.3619\n",
      "Epoch 28/200\n",
      "818/818 - 2s - 3ms/step - loss: 33.1589 - mae: 4.3384\n",
      "Epoch 29/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.9761 - mae: 4.3372\n",
      "Epoch 30/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.7163 - mae: 4.3235\n",
      "Epoch 31/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.5156 - mae: 4.2975\n",
      "Epoch 32/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.3908 - mae: 4.2858\n",
      "Epoch 33/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.2388 - mae: 4.2685\n",
      "Epoch 34/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.2730 - mae: 4.2742\n",
      "Epoch 35/200\n",
      "818/818 - 2s - 3ms/step - loss: 32.1384 - mae: 4.2613\n",
      "Epoch 36/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.9307 - mae: 4.2338\n",
      "Epoch 37/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.9334 - mae: 4.2320\n",
      "Epoch 38/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.6462 - mae: 4.2213\n",
      "Epoch 39/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.6729 - mae: 4.2301\n",
      "Epoch 40/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.4990 - mae: 4.2083\n",
      "Epoch 41/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.6037 - mae: 4.2077\n",
      "Epoch 42/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.4360 - mae: 4.1992\n",
      "Epoch 43/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.3605 - mae: 4.1796\n",
      "Epoch 44/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.2121 - mae: 4.1897\n",
      "Epoch 45/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.1437 - mae: 4.1723\n",
      "Epoch 46/200\n",
      "818/818 - 2s - 3ms/step - loss: 31.3333 - mae: 4.1941\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 14\u001B[0m\n\u001B[0;32m      3\u001B[0m early_stop \u001B[38;5;241m=\u001B[39m EarlyStopping(\n\u001B[0;32m      4\u001B[0m     patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m      5\u001B[0m     restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      6\u001B[0m     monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     11\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     12\u001B[0m                )\n\u001B[1;32m---> 14\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train_processed, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, callbacks\u001B[38;5;241m=\u001B[39m[early_stop])\n\u001B[0;32m     16\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    397\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m begin_step, end_step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[0;32m    398\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(begin_step)\n\u001B[1;32m--> 399\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[0;32m    400\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(end_step, logs)\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:244\u001B[0m, in \u001B[0;36mTensorFlowTrainer._make_function.<locals>.function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mhas_value():\n\u001B[0;32m    243\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m--> 244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m opt_outputs\u001B[38;5;241m.\u001B[39mget_value()\n\u001B[0;32m    245\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m step, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\n\u001B[0;32m    247\u001B[0m         \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_execution), iterator\n\u001B[0;32m    248\u001B[0m     ):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:186\u001B[0m, in \u001B[0;36m_OptionalImpl.get_value\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptionalGetValue\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    184\u001B[0m                     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor]) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[0;32m    185\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 186\u001B[0m     result \u001B[38;5;241m=\u001B[39m gen_optional_ops\u001B[38;5;241m.\u001B[39moptional_get_value(\n\u001B[0;32m    187\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor,\n\u001B[0;32m    188\u001B[0m         name\u001B[38;5;241m=\u001B[39mscope,\n\u001B[0;32m    189\u001B[0m         output_types\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_types(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec),\n\u001B[0;32m    190\u001B[0m         output_shapes\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_shapes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec),\n\u001B[0;32m    191\u001B[0m     )\n\u001B[0;32m    192\u001B[0m   \u001B[38;5;66;03m# NOTE: We do not colocate the deserialization of composite tensors\u001B[39;00m\n\u001B[0;32m    193\u001B[0m   \u001B[38;5;66;03m# because not all ops are guaranteed to have non-GPU kernels.\u001B[39;00m\n\u001B[0;32m    194\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m structure\u001B[38;5;241m.\u001B[39mfrom_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_element_spec, result)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:95\u001B[0m, in \u001B[0;36moptional_get_value\u001B[1;34m(optional, output_types, output_shapes, name)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m     94\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 95\u001B[0m     _result \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_FastPathExecute(\n\u001B[0;32m     96\u001B[0m       _ctx, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptionalGetValue\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, optional, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_types\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     97\u001B[0m       output_types, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_shapes\u001B[39m\u001B[38;5;124m\"\u001B[39m, output_shapes)\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m     99\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:40:57.507639Z",
     "start_time": "2025-11-20T15:40:56.665779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(score)\n",
    "print(mean_squared_error(y_test, y_pred))"
   ],
   "id": "5a4427fd05bff643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m205/205\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n",
      "0.5412287516986318\n",
      "33.73150468039557\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "it takes absurd amount of time to make a very poor predict prediction, probably need to preprocess data again\n",
    "\n",
    "Best score with such settings\n",
    "\n",
    "nodes_number = int((X.shape[1] + 1) * 2/3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape= (X.shape[1],)))\n",
    "\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "\n",
    "model.add(Dense(nodes_number, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "with standard scaler data applied to both X and y\n",
    "\n",
    "0.21329008825613271\n",
    "\n",
    "0.7689129542072395\n",
    "\n",
    "Probably it worth to try use 62 features with location and timestamps excluded. Could possibly apply PCA\n"
   ],
   "id": "b320f1325b72a36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:50:00.036798Z",
     "start_time": "2025-11-14T23:49:58.985808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import Sequential\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 29 15:40:04 2025\n",
    "\n",
    "@author: zemsk\n",
    "\n",
    "\n",
    "Bleaching Presence Detection\n",
    "Target variable: Percent_Bleaching\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"./coral-reef-global-bleaching\"\n",
    "filename_read = os.path.join(path, \"coral.csv\")\n",
    "\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "# # Removed only locations and labels, no real data touched\n",
    "# df.drop(\"Ocean_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Country_Name\", axis=1, inplace=True)\n",
    "# df.drop(\"Sample_ID\", axis=1, inplace=True)\n",
    "# df.drop(\"Date_Year\", axis=1, inplace=True)\n",
    "# df.drop(\"Bleaching_Level\", axis=1, inplace=True)\n",
    "# df.drop(\"Realm_Name\", axis=1, inplace=True)\n",
    "#\n",
    "# cols_to_drop = [\n",
    "#     'Site_ID', 'Data_Source', 'Latitude_Degrees', 'Longitude_Degrees',\n",
    "#     'Reef_ID', 'Ecoregion_Name', 'State_Island_Province_Name',\n",
    "#     'City_Town_Name', 'Site_Name', 'Date', 'Date_Day', 'Date_Month',\n",
    "#     'Site_Comments', 'Sample_Comments', 'Bleaching_Comments'\n",
    "# ]\n",
    "#\n",
    "# df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "# #Percent_Cover is not a best predictor and also contain 30% of its fields as null.\n",
    "# # For the sake of bigger dataset this feature is dropped\n",
    "# df.drop(\"Percent_Cover\", axis=1, inplace=True)\n",
    "# df.drop(\"ClimSST\", inplace=True, axis=1)\n",
    "# df.drop(\"Exposure\", inplace=True, axis=1)\n",
    "# df.drop(\"Temperature_Maximum\", inplace=True, axis=1)\n",
    "#\n",
    "# label_encoder = LabelEncoder()\n",
    "# df[\"Exposure\"] = label_encoder.fit_transform(df[\"Exposure\"])\n",
    "\n",
    "# These features were taken into account that data is nonlinear\n",
    "#df = df[[\"Distance_to_Shore\", \"Temperature_Mean\", \"Turbidity\", \"TSA\", \"Depth_m\", \"Percent_Bleaching\"]]\n",
    "\n",
    "# These features were taken into account that data is linear\n",
    "# df = df[['Cyclone_Frequency', 'Depth_m', 'ClimSST', 'Distance_to_Shore', 'Turbidity', 'TSA', 'Temperature_Mean', 'Percent_Bleaching']]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "\n"
   ],
   "id": "76100a6c4c33eb3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zemsk\\AppData\\Local\\Temp\\ipykernel_16180\\3720938078.py:27: DtypeWarning: Columns (13,15,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename_read)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41361 entries, 0 to 41360\n",
      "Data columns (total 62 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Site_ID                                41361 non-null  int64  \n",
      " 1   Sample_ID                              41361 non-null  int64  \n",
      " 2   Data_Source                            41361 non-null  object \n",
      " 3   Latitude_Degrees                       41361 non-null  float64\n",
      " 4   Longitude_Degrees                      41361 non-null  float64\n",
      " 5   Ocean_Name                             41361 non-null  object \n",
      " 6   Reef_ID                                41361 non-null  object \n",
      " 7   Realm_Name                             41361 non-null  object \n",
      " 8   Ecoregion_Name                         41361 non-null  object \n",
      " 9   Country_Name                           41361 non-null  object \n",
      " 10  State_Island_Province_Name             41361 non-null  object \n",
      " 11  City_Town_Name                         41361 non-null  object \n",
      " 12  Site_Name                              41361 non-null  object \n",
      " 13  Distance_to_Shore                      41361 non-null  object \n",
      " 14  Exposure                               41361 non-null  object \n",
      " 15  Turbidity                              41361 non-null  object \n",
      " 16  Cyclone_Frequency                      41361 non-null  float64\n",
      " 17  Date_Day                               41361 non-null  int64  \n",
      " 18  Date_Month                             41361 non-null  int64  \n",
      " 19  Date_Year                              41361 non-null  int64  \n",
      " 20  Depth_m                                41361 non-null  object \n",
      " 21  Substrate_Name                         41361 non-null  object \n",
      " 22  Percent_Cover                          41361 non-null  object \n",
      " 23  Bleaching_Level                        41361 non-null  object \n",
      " 24  Percent_Bleaching                      41361 non-null  object \n",
      " 25  ClimSST                                41361 non-null  object \n",
      " 26  Temperature_Kelvin                     41361 non-null  object \n",
      " 27  Temperature_Mean                       41361 non-null  object \n",
      " 28  Temperature_Minimum                    41361 non-null  object \n",
      " 29  Temperature_Maximum                    41361 non-null  object \n",
      " 30  Temperature_Kelvin_Standard_Deviation  41361 non-null  object \n",
      " 31  Windspeed                              41361 non-null  object \n",
      " 32  SSTA                                   41361 non-null  object \n",
      " 33  SSTA_Standard_Deviation                41361 non-null  object \n",
      " 34  SSTA_Mean                              41361 non-null  object \n",
      " 35  SSTA_Minimum                           41361 non-null  object \n",
      " 36  SSTA_Maximum                           41361 non-null  object \n",
      " 37  SSTA_Frequency                         41361 non-null  object \n",
      " 38  SSTA_Frequency_Standard_Deviation      41361 non-null  object \n",
      " 39  SSTA_FrequencyMax                      41361 non-null  object \n",
      " 40  SSTA_FrequencyMean                     41361 non-null  object \n",
      " 41  SSTA_DHW                               41361 non-null  object \n",
      " 42  SSTA_DHW_Standard_Deviation            41361 non-null  object \n",
      " 43  SSTA_DHWMax                            41361 non-null  object \n",
      " 44  SSTA_DHWMean                           41361 non-null  object \n",
      " 45  TSA                                    41361 non-null  object \n",
      " 46  TSA_Standard_Deviation                 41361 non-null  object \n",
      " 47  TSA_Minimum                            41361 non-null  object \n",
      " 48  TSA_Maximum                            41361 non-null  object \n",
      " 49  TSA_Mean                               41361 non-null  object \n",
      " 50  TSA_Frequency                          41361 non-null  object \n",
      " 51  TSA_Frequency_Standard_Deviation       41361 non-null  object \n",
      " 52  TSA_FrequencyMax                       41361 non-null  object \n",
      " 53  TSA_FrequencyMean                      41361 non-null  object \n",
      " 54  TSA_DHW                                41361 non-null  object \n",
      " 55  TSA_DHW_Standard_Deviation             41361 non-null  object \n",
      " 56  TSA_DHWMax                             41361 non-null  object \n",
      " 57  TSA_DHWMean                            41361 non-null  object \n",
      " 58  Date                                   41361 non-null  object \n",
      " 59  Site_Comments                          41361 non-null  object \n",
      " 60  Sample_Comments                        41361 non-null  object \n",
      " 61  Bleaching_Comments                     41361 non-null  object \n",
      "dtypes: float64(3), int64(5), object(54)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
